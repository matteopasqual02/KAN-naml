\section{Conclusions}

Kolmogorov-Arnold Networks (KANs) offer an innovative approach to neural network architecture, diverging from Multi-layer Perceptrons (MLPs). Inspired by the Kolmogorov-Arnold representation theorem, KANs replace weight matrices and fixed activation functions with no weights and learnable spline-based functions that enhance expressiveness and adaptability. This unique design enables KANs to model complex, non-linear relationships with fewer parameters, leading to improved generalization and interpretability compared to MLPs. We have also demonstrated that KANs consistently outperform MLPs in non-linear regression and function approximation tasks, achieving lower test loss with reduced depth and complexity.

However, challenges persist in optimizing the training process for KANs. The reliance on spline activation functions introduces computational overhead, making KANs significantly slower than MLPs for comparable parameter counts. The current lack of mature optimization strategies for spline-based architectures further exacerbates this bottleneck. Despite these hurdles, advanced techniques such as sparsification, pruning, and symbolification have shown promise in reducing complexity, improving training efficiency, and providing a more interpretable network.

Looking forward, the potential for further improvement in KANs is immense. Research into accelerated training methods, more efficient spline representations, and scalable regularization techniques could unlock broader adoption and application of KANs across various machine learning tasks. Moreover, their ability to seamlessly integrate advanced techniques and provide symbolic interpretations of learned functions highlights their relevance in pushing the boundaries of interpretable AI.

KANs are not merely an alternative to MLPs but represent a paradigm shift toward more expressive, transparent, and efficient neural network architectures, with significant implications for the future of machine learning \cite{KAN,book1NAML,book2NAML,KArevisited,KAtheorem,bezier,kan_intro}.

