{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMFxOnrXsttr07KWVJMiPeL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["##REQUIREMENTS"],"metadata":{"id":"IUHJ_fGpZou4"}},{"cell_type":"markdown","source":["### Install the required libraries\n","\n","- pykan\n","- torchvision"],"metadata":{"id":"xwjAb4ORy-Oq"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7FqK-kGWufEJ"},"outputs":[],"source":["%pip install pykan\n","%pip install torchvision"]},{"cell_type":"code","source":["#first example\n","from kan import *\n","import numpy as np\n","import matplotlib.pyplot as plt"],"metadata":{"id":"54kJRebcvF96"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#second example\n","from kan import *\n","import torch\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import load_breast_cancer\n","import seaborn as sns"],"metadata":{"id":"2GNXQkpHpC5j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Support functions\n","\n","- fit_plot: plot the train loss and the test loss\n","- plot_correlation: true label vs predicted labels\n","- get data: to obtain the dataset in the correct form\n","- plot_confusion: plot the confusion matrix\n"],"metadata":{"id":"BeIFEfqgWpPH"}},{"cell_type":"code","source":["def plot_fit(fit):\n","    train_loss = [float(val) for val in fit['train_loss']]\n","    test_loss = [float(val) for val in fit['test_loss']]\n","    reg = [float(val) for val in fit['reg']]\n","\n","    plt.figure(figsize=(10, 6))\n","    plt.plot(train_loss, label='Train Loss', marker='o')\n","    plt.plot(test_loss, label='Test Loss', marker='o')\n","\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Value')\n","    plt.title('Training Metrics Over Epochs')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.tight_layout()\n","    plt.show()"],"metadata":{"id":"nNDZi5LNaQyj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_correlation(model,dataset):\n","    train_pred = model(dataset['train_input']).detach().numpy()\n","    test_pred = model(dataset['test_input']).detach().numpy()\n","\n","    fig, axes = plt.subplots(1,2, figsize=(11,5))\n","\n","    axes[0].scatter(dataset['train_label'], train_pred, label=\"train\")\n","    axes[0].plot([0,7],[0,7], color='red')\n","    axes[0].set_xlabel('True Labels')\n","    axes[0].set_ylabel('Predicted Labels')\n","    axes[0].set_title('Scatter Plot - Training Data')\n","    axes[0].legend()\n","    axes[0].grid(True)\n","\n","    axes[1].scatter(dataset['test_label'], test_pred, label=\"test\")\n","    axes[1].plot([0,7],[0,7], color='red')\n","    axes[1].set_xlabel('True Labels')\n","    axes[1].set_ylabel('Predicted Labels')\n","    axes[1].set_title('Scatter Plot - Test Data')\n","    axes[1].legend()\n","    axes[1].grid(True)\n","\n","    plt.tight_layout()\n","    plt.show()"],"metadata":{"id":"8MfYt8XYaTw8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_data(test_split=0.2,random_state=42,device=\"cpu\",is_regression=False):\n","    dataset = load_breast_cancer()\n","    print(f\"Dataset data shape: {dataset.data.shape} and dataset target shape: {dataset.target.shape}\")\n","\n","    y_shape = dataset.target.shape\n","    target  = dataset.target\n","    if not is_regression:\n","        if len(y_shape)<2:\n","            N = len(dataset.target)\n","            unique_values = np.unique(dataset.target)\n","            unique_dic = {_:i for i,_ in enumerate(unique_values)}\n","            encoded = np.zeros((N, len(unique_values)), dtype=int)\n","            for i, value in enumerate(dataset.target):\n","                encoded[i, unique_dic[value]] = 1\n","                target = encoded\n","\n","    X_train, X_test, y_train, y_test = train_test_split(dataset.data,target, test_size=test_split, random_state=random_state)\n","    mean = X_train.mean(0)\n","    std =  X_train.std(0)\n","    X_train = (X_train - mean)/std\n","    X_test = (X_test - mean)/std\n","\n","    dataset ={'train_input':X_train ,'train_label':y_train ,'test_input':X_test ,'test_label':y_test}\n","    for k,v in dataset.items():\n","        dataset[k] = torch.tensor(v,dtype=torch.float32).to(device)\n","\n","    print(f\"Dataset Imported\")\n","    return dataset"],"metadata":{"id":"FwzJxsmyU7By"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_confusion_accuracy(model,dataset):\n","    train_true = dataset['train_label'].argmax(1)\n","    train_pred = model(dataset['train_input']).cpu().detach().numpy().round().argmax(1)\n","    cm_train = confusion_matrix(train_true, train_pred)\n","    test_true = dataset['test_label'].argmax(1)\n","    test_pred = model(dataset['test_input']).cpu().detach().numpy().round().argmax(1)\n","    cm_test = confusion_matrix(test_true, test_pred)\n","\n","    train_accuracy = accuracy_score(train_true, train_pred)\n","    test_accuracy = accuracy_score(test_true, test_pred)\n","\n","    print(\"ACCURACY\")\n","    print(f\"Training Accuracy: {train_accuracy}\")\n","    print(f\"Test Accuracy: {test_accuracy}\")\n","\n","    print(\"Confusion Matrix - Training Data and Test Data\")\n","    fig, axes = plt.subplots(1,2, figsize=(10,6))\n","\n","    plt.subplot(1,2, 1)\n","    sns.set(font_scale=1.2)\n","    sns.heatmap(cm_train, annot=True, fmt='d', cmap='Blues', cbar=False,\n","                xticklabels=['Class 0', 'Class 1'],\n","                yticklabels=['Class 0', 'Class 1'])\n","    plt.xlabel('Predicted Labels')\n","    plt.ylabel('True Labels')\n","    plt.title('Confusion Matrix - Training Data')\n","\n","    plt.subplot(1,2, 2)\n","    sns.set(font_scale=1.2)\n","    sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues', cbar=False,\n","                xticklabels=['Class 0', 'Class 1'],\n","                yticklabels=['Class 0', 'Class 1'])\n","    plt.xlabel('Predicted Labels')\n","    plt.ylabel('True Labels')\n","    plt.title('Confusion Matrix - Test Data')\n","\n","    plt.tight_layout()\n","    plt.show()"],"metadata":{"id":"YZhkO_NUa2Na"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# KAN: Kolmogorov Arnold Network - REGRESSION EXAMPLE"],"metadata":{"id":"h5RCME9muyQO"}},{"cell_type":"markdown","source":["## KAN Model\n","Create a KAN model with the specified hyperparameters:\n","\n","- L = 3: This indicates the number of layers in the network.\n","- N = [2, 5, 1]: This specifies the number of neurons in each layer:\n","    - 2: Number of input neurons (2D input).\n","    - 5: Number of neurons in the hidden layer.\n","    - 1: Number of output neurons (1D output).\n","- k = 3: This specifies that we are using cubic splines (degree 3) for the hidden layer activations.\n","- G = 5: This defines the number of grid intervals (5 intervals) for the knots in the input space.\n","\n","Using the function ` KAN(width,grid,k,seed) `"],"metadata":{"id":"0D1VGHGzwOH_"}},{"cell_type":"code","source":["width = [2,5,1]\n","grid = 5\n","k = 3\n","seed = 0\n","\n","model = KAN(width=width, grid=grid, k=k, seed=seed)"],"metadata":{"id":"EI733riSvBZ-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## KAN Dataset\n","\n","create the dataset on the function $f$:\n","\n","$$ f(x,y) = e^{\\sin(\\pi x) + y^2}$$"],"metadata":{"id":"YFC5GZYnzNjB"}},{"cell_type":"code","source":["f = lambda x: torch.exp(torch.sin(torch.pi*x[:,[0]]) + x[:,[1]]**2)\n","\n","dataset = create_dataset(f, n_var=2)\n","print(\"Dataset input shape:\", dataset['train_input'].shape)\n","print(\"Dataset output shape:\", dataset['train_label'].shape)"],"metadata":{"id":"di9uJoU_zMGo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Plot the network"],"metadata":{"id":"SLWm3vZL0DTg"}},{"cell_type":"code","source":["model(dataset['train_input']);\n","print(\"Model initalized\")\n","model.plot()"],"metadata":{"id":"bx6vqJQXz7u6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## KAN Training with Regularization\n","\n","Train the KAN on the dataset using:\n","- Optimization Algorithm: L-BFGS (a second-order optimization method).\n","- Steps: 20 iterations.\n","- Sparsity Regularization:\n","    - lambda (lamb): Regularization parameter set to 0.01.\n","    - Entropy (lamb_entropy): Regularization parameter for entropy set to 10.\n","\n","Using the function:  ` model.fit(dataset, opt, steps, lamb, lamb_entropy) `"],"metadata":{"id":"7ujC4j9z0LeR"}},{"cell_type":"code","source":["opt = \"LBFGS\"\n","steps = 50\n","lamb = 0.01\n","lamb_entropy = 10.\n","\n","fit = model.fit(dataset, opt=opt, steps=steps, lamb=lamb, lamb_entropy=lamb_entropy)\n","plot_fit(fit)"],"metadata":{"id":"5zIn7LtK1S2x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Model trained using {opt} with {steps} steps\")\n","print(f\"Regularization parameters: lambda = {lamb}, lambda_entropy = {lamb_entropy}\")\n","model.plot()"],"metadata":{"id":"WPrzHPpH4-aB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_correlation(model,dataset)"],"metadata":{"id":"P_W0U9jCmpwy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## KAN Pruning\n","\n","Prune the KAN network using the prune function: ` model.prune() `\n","\n","Then re-train the model to increase accuracy"],"metadata":{"id":"OBsC8HS3dbIY"}},{"cell_type":"code","source":["model = model.prune()\n","print(\"Model pruned\")\n","model.plot()"],"metadata":{"id":"tmbckQ1jd_Gj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fit = model.fit(dataset, opt=opt, steps=steps)\n","plot_fit(fit)"],"metadata":{"id":"PpCJN4nrezKh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Model re-trained after pruning using {opt} with {steps} steps\")\n","model.plot()"],"metadata":{"id":"WV6PXzCLfUXR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_correlation(model,dataset)"],"metadata":{"id":"b3tBUdAroE4X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## KAN Symbolic Regression\n","\n","Use Automatic symbolic regression giving a set of functions in a library.\n","\n","Using the function: ` model.auto_symbolic(lib) `\n","\n","Then re-train the model to increase accuracy and plot the symbolic formula"],"metadata":{"id":"ibqlSG7ofb7l"}},{"cell_type":"code","source":["lib = ['x','x^2','x^3','x^4','exp','log','sqrt','tanh','sin','abs']\n","print(f\"Symbolic regression using {lib} libray\")\n","model.auto_symbolic(lib=lib)"],"metadata":{"id":"Mrx9aoIFgcWZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Symbolic regression model\")\n","model.plot()"],"metadata":{"id":"jR8IpNjZiENd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_correlation(model,dataset)"],"metadata":{"id":"jX2U7Di7oNnC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Symbolic formula\")\n","ex_round(model.symbolic_formula()[0][0],2)"],"metadata":{"id":"3otWUP1og5p0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# KAN: Kolmogorov Arnold Network - CANCER ANALISYS"],"metadata":{"id":"aM2W6XORoxoE"}},{"cell_type":"markdown","source":["##CANCER DATASET\n","\n","Import the cancer dataset *load_breast_cancer*  from *sklearn.datasets* and format properly.\n","\n","Then divide it in train and test sets."],"metadata":{"id":"HO6E9m3diOi9"}},{"cell_type":"code","source":["dataset = get_data(test_split=0.2)"],"metadata":{"id":"XUBoXys5fYCk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## CANCER MODEL\n","Create a KAN model with the specified hyperparameters:\n","\n","- L = 3: This indicates the number of layers in the network.\n","- N = [30, 4, 2]: This specifies the number of neurons in each layer.\n","- k = 3: This specifies that we are using cubic splines.\n","- G = 3: This defines the number of grid intervals.\n","\n","Using the function ` KAN(width,grid,k,seed) `"],"metadata":{"id":"euJR08DpkA9U"}},{"cell_type":"code","source":["width = [30, 4, 2]\n","grid = 3\n","k = 3\n","\n","model_cancer = KAN(width=width, grid=grid, k=k)"],"metadata":{"id":"3cWKvbv5j4_l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Dataset input shape:\", dataset['train_input'].shape)\n","print(\"Dataset output shape:\", dataset['train_label'].shape)"],"metadata":{"id":"bYdMlti3umTU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## CANCER TRAINING\n","\n","Train the KAN on the dataset using:\n","- Optimization Algorithm: L-BFGS (a second-order optimization method).\n","- Steps: 20 iterations.\n","- Sparsity Regularization:\n","    - lambda (lamb): Regularization parameter set to 0.01.\n","    - Entropy (lamb_entropy): Regularization parameter for entropy set to 10.\n","\n","- Learning rate at 0.01\n","- Cross entropy as loss funtion\n","\n","Using the function:  ` model.fit(dataset, opt, steps, lamb, lamb_entropy, lr, loss_fn) `"],"metadata":{"id":"XsklTzeCzGVr"}},{"cell_type":"code","source":["opt = \"LBFGS\"\n","steps = 20\n","lamb = 0.01\n","lamb_entropy = 10.\n","lr = 0.01\n","loss_fn = torch.nn.CrossEntropyLoss()\n","\n","fit = model_cancer.fit(dataset, opt=opt, steps=steps, lamb=lamb, lamb_entropy=lamb_entropy, lr=lr, loss_fn=loss_fn)\n","plot_fit(fit)"],"metadata":{"id":"twbzHvserFme"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Model trained using {opt} with {steps} steps\")\n","print(f\"Regularization parameters: lambda = {lamb}, lambda_entropy = {lamb_entropy}\")\n","print(f\"Learning rate: {lr}\")\n","model_cancer.plot()"],"metadata":{"id":"OKRgFBruuNNr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## CANCER RESULT AFTER TRAINING\n","\n","- Plot the confusion matrix of the training set and the test set\n","\n","- Compute the accuracy of the training set and the test set"],"metadata":{"id":"kdpinRo0T_BG"}},{"cell_type":"code","source":["plot_confusion_accuracy(model_cancer,dataset)"],"metadata":{"id":"lYyLKQIHUB-9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## CANCER PRUNING\n","\n","Prune the KAN network using the prune function: ` model.prune() `\n","\n","Then re-train the model to increase accuracy"],"metadata":{"id":"TWE0zaFSzeE1"}},{"cell_type":"code","source":["model_cancer_pruned = model_cancer.prune()"],"metadata":{"id":"-Gp14NXIutEV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["opt = \"LBFGS\"\n","steps = 20\n","lamb = 0.01\n","lamb_entropy = 10.\n","lr = 0.01\n","device = \"cpu\"\n","loss_fn = torch.nn.CrossEntropyLoss()\n","\n","fit = model_cancer_pruned.fit(dataset, opt=opt, steps=steps, lamb=lamb, lamb_entropy=lamb_entropy, lr=lr, loss_fn=loss_fn)\n","plot_fit(fit)"],"metadata":{"id":"es3nkgfQu1ds"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Model re-trained after pruning using {opt} with {steps} steps\")\n","print(f\"Regularization parameters: lambda = {lamb}, lambda_entropy = {lamb_entropy}\")\n","print(f\"Learning rate: {lr}\")\n","model_cancer_pruned.plot()"],"metadata":{"id":"rcAXLNiavwxr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## CANCER RESULT AFTER PRUNING\n","\n","- Plot the confusion matrix of the training set and the test set\n","\n","- Compute the accuracy of the training set and the test set"],"metadata":{"id":"DkffONKNzkra"}},{"cell_type":"code","source":["plot_confusion_accuracy(model_cancer_pruned,dataset)"],"metadata":{"id":"NZHxyq4FwAtx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## CANCER SYMBOLIC REGRESSION\n","Use Automatic symbolic regression giving a set of functions in a library.\n","\n","Using the function: ` model.auto_symbolic(lib) `\n","\n","With this dataset we dont't notice a great advantage using symbolic regression"],"metadata":{"id":"cKHzU2GaztB_"}},{"cell_type":"code","source":["lib = ['x','x^2','x^3','x^4','exp','log','sqrt','tanh','sin','abs']\n","model_cancer_pruned.auto_symbolic(lib=lib)"],"metadata":{"id":"CzWqXYDbxBwg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Symbolic formula\")\n","ex_round(model_cancer_pruned.symbolic_formula()[0][0],2)"],"metadata":{"id":"2qGTuXP2z0iN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## CANCER RESULT AFTER SYMBOLIC REGRESSION\n","\n","- Plot the confusion matrix of the training set and the test set\n","\n","- Compute the accuracy of the training set and the test set"],"metadata":{"id":"qjp3SLu9TkXl"}},{"cell_type":"code","source":["plot_confusion_accuracy(model_cancer_pruned,dataset)"],"metadata":{"id":"Lm1eFQddcMgW"},"execution_count":null,"outputs":[]}]}